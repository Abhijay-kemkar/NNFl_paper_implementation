{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAa-1MA0wcMd"
      },
      "source": [
        "#This notebook takes in as input path of two folders, one folder containing all the images and the other folder having all the masks with the same name.\n",
        "#This same notebook can be used to prepare the training and validation data for both the challenges."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr1vVhs2DuYx"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from PIL import Image, ImageSequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7igvX4_ED_nk"
      },
      "source": [
        "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
        "    \"\"\"Function to do the elastic transformation\n",
        "       image : The image you want to perform the elastic transformation on\n",
        "       rest params are the parameters which defines the morphological operations\n",
        "    \"\"\"\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    shape = image.shape\n",
        "    shape_size = shape[:2]\n",
        "\n",
        "    # Random affine\n",
        "    center_square = np.float32(shape_size) // 2\n",
        "    square_size = min(shape_size) // 3\n",
        "    pts1 = np.float32([center_square + square_size, [center_square[0] + square_size, center_square[1] - square_size],\n",
        "                       center_square - square_size])\n",
        "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "    M = cv2.getAffineTransform(pts1, pts2)\n",
        "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dz = np.zeros_like(dx)\n",
        "\n",
        "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "    indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
        "\n",
        "\n",
        "# Define function to draw a grid\n",
        "def draw_grid(im, grid_size):\n",
        "    \"\"\" Function to draw the grid lines\"\"\"\n",
        "    for i in range(0, im.shape[1], grid_size):\n",
        "        cv2.line(im, (i, 0), (i, im.shape[0]), (0,100,255),2)\n",
        "    for j in range(0, im.shape[0], grid_size):\n",
        "        cv2.line(im, (0, j), (im.shape[1], j), (0,100,255),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANg6M40ACDE1"
      },
      "source": [
        "No_img = 10         # The actual number of augmentated images generated per image is No_img + 1\n",
        "\n",
        "class DataAug():\n",
        "    \"\"\"\n",
        "    This class generates augmentation for each image in the dataset using the keras's ImageDataGenerator. For each image in the dataset, a folder will be created with the same name as image's containing all the augmentations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 train_path=\"/content/unet/data/membrane/train/image\",    #training images path\n",
        "                 label_path=\"/content/unet/data/membrane/train/label\",    #training masks path\n",
        "                 merge_path=\"/content/unet/data/membrane/train/merge\",    # after this directories will be created, just mention the location where you want it to be created \n",
        "                 aug_merge_path=\"/content/unet/data/membrane/train/aug_merge\",\n",
        "                 aug_train_path=\"/content/unet/data/membrane/train/aug_train\",\n",
        "                 aug_label_path=\"/content/unet/data/membrane/train/aug_label\",\n",
        "                 img_type=\"png\"):\n",
        "\n",
        "        # get all picutre under path with specific file extension\n",
        "        self.train_imgs = glob.glob(train_path + \"/*.\" + img_type)\n",
        "        self.label_imgs = glob.glob(label_path + \"/*.\" + img_type)\n",
        "\n",
        "        self.train_path = train_path\n",
        "        self.label_path = label_path\n",
        "        self.merge_path = merge_path\n",
        "        self.img_type = img_type\n",
        "        self.aug_merge_path = aug_merge_path\n",
        "        self.aug_train_path = aug_train_path\n",
        "        self.aug_label_path = aug_label_path\n",
        "        self.slices = len(self.train_imgs)\n",
        "\n",
        "        # image data generator parameter\n",
        "        self.datagen = ImageDataGenerator(\n",
        "            rotation_range=0.2,\n",
        "            width_shift_range=0.05,\n",
        "            height_shift_range=0.05,\n",
        "            shear_range=0.08,\n",
        "            zoom_range=0.08,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode='nearest')\n",
        "\n",
        "        self.create_dir(self.merge_path)\n",
        "        self.create_dir(self.aug_merge_path)\n",
        "        self.create_dir(self.aug_train_path)\n",
        "        self.create_dir(self.aug_label_path)\n",
        "    \n",
        "    def create_dir(self, path):\n",
        "        if not os.path.lexists(path):\n",
        "                os.mkdir(path)\n",
        "\n",
        "    def augmentation(self):\n",
        "\n",
        "        if len(self.train_imgs) != len(self.label_imgs) or len(self.train_imgs) == 0 or len(self.label_imgs) == 0:\n",
        "            print(\"trains can't match labels\")\n",
        "            return 0\n",
        "\n",
        "        print(\"len of trains: \", len(self.train_imgs))\n",
        "\n",
        "        for num_of_picture in range(len(self.train_imgs)):\n",
        "            img_t = load_img(self.train_path + \"/\" + str(num_of_picture) + \".\" + self.img_type)\n",
        "            img_l = load_img(self.label_path + \"/\" + str(num_of_picture) + \".\" + self.img_type)\n",
        "            x_t = img_to_array(img_t)\n",
        "            x_l = img_to_array(img_l)\n",
        "\n",
        "            # Merge image\n",
        "            x_t[:, :, 2] = x_l[:, :, 0]     # last channel of x_t is label --> x_t is called merged img # merging the image so as to perform both elastic transformation and overlap tiling on both of the image and mask together. \n",
        "\n",
        "            img_tmp = array_to_img(x_t)\n",
        "            img_tmp.save(self.merge_path + \"/\" + str(num_of_picture) + \".\" + self.img_type)\n",
        "            img = x_t\n",
        "            img = img.reshape((1,) + img.shape)\n",
        "\n",
        "            savedir = self.aug_merge_path + \"/\" + str(num_of_picture)\n",
        "            self.create_dir(savedir)\n",
        "            \n",
        "            print(\"Doing augmentation at picture: \", str(num_of_picture))\n",
        "            self.do_augmentation(img, savedir, str(num_of_picture), 1, self.img_type)\n",
        "        \n",
        "        self.split_merge_image()\n",
        "    \n",
        "    def split_merge_image(self):\n",
        "    \"\"\"\n",
        "\t\tSplit merged image apart\n",
        "\t\t\"\"\"\n",
        "\n",
        "        for num_of_picture in range(self.slices):        \n",
        "            path = self.aug_merge_path + \"/\" + str(num_of_picture)\n",
        "            train_imgs = glob.glob(path + \"/*.\" + self.img_type)    # adding subfolderes \n",
        "\n",
        "            savedir = self.aug_train_path + \"/\" + str(num_of_picture)\n",
        "            self.create_dir(savedir)\n",
        "\n",
        "            savedir = self.aug_label_path + \"/\" + str(num_of_picture)\n",
        "            self.create_dir(savedir)\n",
        "\n",
        "            print(\"len of split: \", len(train_imgs))\n",
        "\n",
        "            for imgname in train_imgs:\n",
        "\n",
        "                \n",
        "                \n",
        "                midname = imgname[imgname.rindex(\"/\") + 1:imgname.rindex(\n",
        "                    \".\" + self.img_type)]\n",
        "                img = cv2.imread(imgname)\n",
        "                img_train = img[:, :, 2]  #cv2 read image rgb->bgr\n",
        "                img_label = img[:, :, 0]\n",
        "            \n",
        "                cv2.imwrite(self.aug_train_path + \"/\" + str(num_of_picture) + \"/\" + midname + \"_train\"\n",
        "                            + \".\" + self.img_type, img_train)\n",
        "                cv2.imwrite(self.aug_label_path + \"/\" + str(num_of_picture) + \"/\" + midname + \"_label\"\n",
        "                            + \".\" + self.img_type, img_label)\n",
        "\n",
        "\n",
        "class DataProcess():\n",
        "    def __init__(self,\n",
        "                 out_rows=512,  #size of image\n",
        "                 out_cols=512,\n",
        "                 data_path=\"/content/unet/data/membrane/train/aug_train\",  #directory containing the augmentated subfolders of images\n",
        "                 label_path=\"/content/unet/data/membrane/train/aug_label\", #directory containing the augmentated subfolders of labels\n",
        "                 npy_path=\"/content/drive/MyDrive/nnfl_final_new_data\",    #directory where you want to store the final .npy files of training and validation sets\n",
        "                 img_type=\"png\",\n",
        "                 img_No_train=0,\n",
        "                 img_No_val=0,\n",
        "                 extra_padding=184):\n",
        "\n",
        "        self.out_rows = out_rows\n",
        "        self.out_cols = out_cols\n",
        "        self.data_path = data_path\n",
        "        self.label_path = label_path\n",
        "        self.img_type = img_type\n",
        "        self.npy_path = npy_path\n",
        "        self.img_No_train = (No_img + 1) * 25      # spiliting the dataset into training and validation\n",
        "        self.img_No_val = (No_img + 1) * 30 - self.img_No_train\n",
        "        self.extra_padding = extra_padding\n",
        "\n",
        "    def input_filled_mirroring(self, x, e = 92):      # Overlap-tile strategy\n",
        "        w, h = np.shape(x)[0], np.shape(x)[1]\n",
        "        y = np.zeros((h + e * 2, w + e * 2))\n",
        "        y[e:h + e, e:w + e] = x\n",
        "        y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically\n",
        "        y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically\n",
        "        y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally\n",
        "        y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally\n",
        "        return y\n",
        "\n",
        "    def create_training_data(self):\n",
        "        extra = self.extra_padding\n",
        "        print('-' * 30)\n",
        "        print('Creating training images...')\n",
        "        print('-' * 30)\n",
        "\n",
        "        ET_params = np.array([[2, 0.08, 0.08], [2, 0.05, 0.05], [3, 0.07, 0.09], [3, 0.12, 0.07]]) * self.out_cols    #This are the different parameters which with we will be doing the elastic transformation. here 4 parameters and 1 original image.\n",
        "                                                                                                                      #Therefore for every augemntated image more 5 images will be generated. ( 1 original + 4 elastic deformed)\n",
        "        len_scaled = len(ET_params) + 1\n",
        "\n",
        "        imgdatas = np.ndarray(\n",
        "            (self.img_No_train*len_scaled, 1, self.out_rows+extra, self.out_cols+extra), dtype=np.uint8)\n",
        "        imglabels = np.ndarray(\n",
        "            (self.img_No_train*len_scaled, 1, self.out_rows, self.out_cols), dtype=np.uint8)\n",
        "\n",
        "        imgdatas_val = np.ndarray(\n",
        "            (self.img_No_val*len_scaled, 1, self.out_rows + extra, self.out_cols + extra), dtype=np.uint8)\n",
        "        imglabels_val = np.ndarray(\n",
        "            (self.img_No_val*len_scaled, 1, self.out_rows, self.out_cols), dtype=np.uint8)\n",
        "\n",
        "        index = 0\n",
        "        import time\n",
        "        start = time.time()\n",
        "\n",
        "        for num_of_picture in range(30):\n",
        "            train_foldername = self.data_path + \"/\" + str(num_of_picture)\n",
        "            label_foldername = self.label_path + \"/\" + str(num_of_picture)\n",
        "            imgs = glob.glob(train_foldername + \"/*.\" + self.img_type)\n",
        "\n",
        "            for imgname in imgs:\n",
        "                # print \"imgname: \", imgname\n",
        "                midname = imgname[imgname.rindex('/') + 1:]\n",
        "                img_name_only = midname[0:midname.rindex(\"_\")]\n",
        "\n",
        "                train_img_path = train_foldername + \"/\" + img_name_only + \"_train.\" + self.img_type\n",
        "                label_img_path = label_foldername + \"/\" + img_name_only + \"_label.\" + self.img_type\n",
        "                img = load_img(train_img_path, grayscale=True)\n",
        "                label = load_img(label_img_path, grayscale=True)\n",
        "\n",
        "                img = np.array(img)         # size of 512x512\n",
        "                label = np.array(label)     # size of 512x512\n",
        "\n",
        "                #  Doing elastic transform \n",
        "                im_merge = np.concatenate((img[..., None], label[..., None]), axis=2)\n",
        "            \n",
        "                for k in range(len(ET_params) + 1):\n",
        "                    if k > 0:   # index 0 is for the original image\n",
        "                        im_merge_t = elastic_transform(im_merge, ET_params[k-1,0], ET_params[k-1,1],ET_params[k-1,2])\n",
        "                        # Split image and mask\n",
        "                        img = im_merge_t[..., 0]\n",
        "                        label = im_merge_t[..., 1]\n",
        "\n",
        "                    # original code for only 1 image augmentation\n",
        "                    img = self.input_filled_mirroring(img)\n",
        "                    img = np.expand_dims(img,0)\n",
        "                    label = np.expand_dims(label,0)\n",
        "                    if index < self.img_No_train*len_scaled:\n",
        "                        imglabels[index] = label/255\n",
        "                        imgdatas[index] = img\n",
        "                    elif (index-self.img_No_train*len_scaled) == 1275 :\n",
        "                        ;\n",
        "                    else:\n",
        "                        imglabels_val[index-self.img_No_train*len_scaled] = label/255 # save validation data\n",
        "                        imgdatas_val[index-self.img_No_train*len_scaled] = img\n",
        "                    index += 1\n",
        "                    # print(\"index: \", index)\n",
        "                    if (index + 1) % 10 == 0: print(\"Processed: %d/%d...Time passed: %.5f mins\" % (index + 1,\n",
        "                            self.img_No_train*len_scaled + self.img_No_val*len_scaled, (time.time() - start)/60.0))\n",
        "\n",
        "        print('loading done')\n",
        "        print('Start Saving processing....')\n",
        "        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
        "        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
        "        np.save(self.npy_path + '/imgs_val.npy', imgdatas_val)            #saving the images in .npy format after doing elastic transform and overlap tiling\n",
        "        np.save(self.npy_path + '/imgs_mask_val.npy', imglabels_val)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "\n",
        "def image_preview(data):\n",
        "    plt.imshow(data)\n",
        "    plt.colorbar()\n",
        "\n",
        "def image_save(data, filename):\n",
        "    plt.imshow(data)\n",
        "    plt.colorbar()\n",
        "    plt.savefig(filename)\n",
        "\n",
        "def augmentation(trains, labels):\n",
        "    \"\"\"\n",
        "    Doing data augmetation using keras.preprocessing.image.ImageDataGenerator\n",
        "    \"\"\"\n",
        "\n",
        "    assert(len(trains) == len(labels)), \"trains can not match labels\"\n",
        "\n",
        "    print('Total trains: ', len(trains))\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "            rotation_range=0.2,\n",
        "            width_shift_range=0.05,\n",
        "            height_shift_range=0.05,\n",
        "            shear_range=0.08,\n",
        "            zoom_range=0.08,\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            fill_mode='nearest')\n",
        "\n",
        "    seed = 1\n",
        "    batch_size = 1\n",
        "    epoch = 50\n",
        "    datagen_generator = datagen.flow(trains, labels, batch_size=batch_size, seed=seed)\n",
        "\n",
        "    tmp_x = list()\n",
        "    tmp_y = list()\n",
        "    i = 0\n",
        "    for batch_x, batch_y in datagen_generator:\n",
        "        tmp_x += list(batch_x)\n",
        "        tmp_y += list(batch_y)\n",
        "        i += 1\n",
        "        if i >= epoch:\n",
        "            return np.array(tmp_x), np.array(tmp_y)\n",
        "\n",
        "def split_image2_4patch(x, y):          #the splitting of the overlapped tiled image \n",
        "    #processing_set = zip(x, y)         \n",
        "    tmp_x = list()\n",
        "    tmp_y = list()\n",
        "    i = 0 \n",
        "    for (image, mask) in zip(x , y):\n",
        "        tmp_x.append(image[0:572, 0:572])\n",
        "        tmp_y.append(mask[0:388, 0:388])\n",
        "        tmp_x.append(image[0:572, 124:696])\n",
        "        tmp_y.append(mask[0:388, 124:512])\n",
        "        tmp_x.append(image[124:696, 0:572])\n",
        "        tmp_y.append(mask[124:512, 0:388])\n",
        "        tmp_x.append(image[124:696, 124:696])\n",
        "        tmp_y.append(mask[124:512, 124:512])\n",
        "         \n",
        "    return np.array(tmp_x), np.array(tmp_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNV9XvT54fSu"
      },
      "source": [
        "aug = DataAug()\n",
        "aug.augmentation()    # Doing Augmentation\n",
        "\n",
        "dp = DataProcess()     #Doing Elastic Transform and Overlap image tilling \n",
        "dp.create_training_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1rXWVo04SdC"
      },
      "source": [
        "#The following commands needs to be repeated for training and the validation set\n",
        "\n",
        "trains = np.load('/content/drive/MyDrive/nnfl_final_new_data/imgs_train.npy')\n",
        "labels = np.load('/content/drive/MyDrive/nnfl_final_new_data/imgs_mask_train.npy') # loding the saved .npy array (these must have been generated using the above classes)\n",
        "print('Trains shape: ', trains.shape)\n",
        "print('Labels shape: ', labels.shape)\n",
        "  \n",
        "\n",
        "trains = trains[:,0,:,:]\n",
        "trains = trains.reshape(trains.shape + (1,))\n",
        "labels = labels[:,0,:,:]                                    #making it in the format of (Total number of images,696,696,1) and (Total number of the masks,512,512,1) for training in the model\n",
        "labels = labels.reshape(labels.shape + (1,))\n",
        "print('Trains shape: ', trains.shape)\n",
        "print('Labels shape: ', labels.shape)\n",
        "\n",
        "X, Y = split_image2_4patch(trains[:,:,:,:], labels[:,:,:,:])    #performing overlapping tiliing. \n",
        "print('X shape: ', X.shape) # 572 x 572\n",
        "print('Y shape: ', Y.shape) # 388 x 388\n",
        "\n",
        "np.save('/content/drive/MyDrive/nnfl_final_data/imgs_train2.npy', X)\n",
        "np.save('/content/drive/MyDrive/nnfl_final_data/imgs_mask_train2.npy', Y)  # use this to save the final data as .npy file."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}